Face recognition has become a widespread technology everywhere. It is not only being used to grant access to different places but is also considered useful in identifying prospective threats by keeping track of the movements of people. However, these days more and more people have started wearing masks to protect themselves from harmful fumes, pollution, viruses, etc. When it comes to masked-face recognition, models trained for unmasked face recognition task fails to perform to the desired level. Occlusion caused due to the usage of the mask makes it tough for machine learning algorithms to differentiate between genuine and impostor pairs of face images. This work studies a Siamese network-based model for the development of a robust masked face recognition system that can give accurate results in tasks such as face verification - one on one mapping and face recognition - one to many mapping. We also use pre-trained attention-based layers to build the core model of the network architecture to focus on the relevant portion of face images. The study starts with using the pre-trained SENet50 model for getting the face embeddings to training the last 70 layers of the pre-trained model with Siamese architecture and custom loss, achieving the highest difference between the median Genuine and Impostor distances as 0.441. The experimental results conclude that the attention based core model aids to focus more on regions in and around the eyes rather than on the occluded areas for the masked face recognition task.